---
title: ai hasn't taken human labor out of the equation
published: 2024-01-14T23:23:26.551Z
created: 2024-01-14T23:23:26.551Z
migrated: 2024-09-17T01:07:22-05:00
aliases:
- ai hasn't taken human labor out of the equation
crossposts:
- url: https://cohost.org/exodrifter/post/4177201-ai-hasn-t-taken-huma
  time: 2024-01-14T23:23:26.551Z
tags:
- cohost
---

# ai hasn't taken human labor out of the equation

I think a lot of people really underestimate how difficult it is to translate _what we want in our heads_ to _having someone else understand it_. However, this is problem is treated as practically non-existent whenever AI is marketed as a tool for creating content.

This conceit reveals itself as soon as a text prompt is used as the input. The idea here, if it isn't obvious enough, is that a text prompt is the easiest, fastest way for you to get what you want from the AI. However, the languages we use still have a TON of ambiguities. It's very difficult to specify exactly what you want to someone, AI or not.

This is why you'll see, like what is being done with AI right now, a lot of time being spent trying to figure out how to reduce that ambiguity when trying to get an AI to do whatever the creators think "the right thing" is. You get AI models trained to make specific kinds of things, you get more ways to nudge the AI in what is hopefully the right direction, and you get the creation of the "prompt engineer" role whose purpose is to figure out how to speak to the AI in the "right way" to produce "the right thing".

Honestly, I imagine most situations where companies try to use AI look like this...
> company: Wow, AI can replace artists!
> company: Oh, actually, I can't get the AI to do what I want. Maybe we want a prompt engineer?
> company: But if we want to replace artists to lower our payroll, [we'll have to pay them less than we pay artists for this to be worth it](https://twitter.com/GlynnTarrant/status/1746285831462039963).
> prompt engineer: oh no

...and now, the company is talking to a human again, instead of an AI.  Why? **Because they feel like a human can understand them better than an AI can.** But, well, that's at least one reason for why you had an artist in the first place.

And now, I'm going to quote the article [_On the foolishness of "natural language processing"_](https://www.cs.utexas.edu/users/EWD/transcriptions/EWD06xx/EWD667.html) by Dijkstra, because it's so based:
> The virtue of formal texts is that their manipulations, in order to be legitimate, need to satisfy only a few simple rules; they are, when you come to think of it, an amazingly effective tool for ruling out all sorts of nonsense that, when we use our native tongues, are almost impossible to avoid.
